{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use MCP in OpenAI Agents SDK\n",
    "\n",
    "1. Create a Client\n",
    "\n",
    "2. Have it spawn a server\n",
    "\n",
    "3. Collect the tools that the server can use\n",
    "\n",
    "Let's try the Fetch mcp-server that we looked at last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_tools(params):\n",
    "    async with MCPServerStdio(params=params) as server:\n",
    "        tools = await server.list_tools()\n",
    "\n",
    "    for tool in tools:\n",
    "        print(f\"{tool.name}: {tool.description.replace('\\n',' ')}\")\n",
    "\n",
    "    return tools;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch: Fetches a URL from the internet and optionally extracts its contents as markdown.  Although originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.\n"
     ]
    }
   ],
   "source": [
    "fetch_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "async with MCPServerStdio(params=fetch_params) as server:\n",
    "    fetch_tools = await server.list_tools()\n",
    "\n",
    "for tool in fetch_tools:\n",
    "    print(f\"{tool.name}: {tool.description.replace('\\n',' ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now repeat for 3 more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puppeteer_navigate: Navigate to a URL\n",
      "puppeteer_screenshot: Take a screenshot of the current page or a specific element\n",
      "puppeteer_click: Click an element on the page\n",
      "puppeteer_fill: Fill out an input field\n",
      "puppeteer_select: Select an element on the page with Select tag\n",
      "puppeteer_hover: Hover an element on the page\n",
      "puppeteer_evaluate: Execute JavaScript in the browser console\n"
     ]
    }
   ],
   "source": [
    "puppeteer_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-puppeteer\"]}\n",
    "\n",
    "puppeteer_tools =await get_tools(puppeteer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'object',\n",
       " 'properties': {'url': {'type': 'string', 'description': 'URL to navigate to'},\n",
       "  'launchOptions': {'type': 'object',\n",
       "   'description': \"PuppeteerJS LaunchOptions. Default null. If changed and not null, browser restarts. Example: { headless: true, args: ['--no-sandbox'] }\"},\n",
       "  'allowDangerous': {'type': 'boolean',\n",
       "   'description': 'Allow dangerous LaunchOptions that reduce security. When false, dangerous args like --no-sandbox will throw errors. Default false.'}},\n",
       " 'required': ['url']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puppeteer_tools[0].inputSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_file: Read the complete contents of a file from the file system. Handles various text encodings and provides detailed error messages if the file cannot be read. Use this tool when you need to examine the contents of a single file. Only works within allowed directories.\n",
      "read_multiple_files: Read the contents of multiple files simultaneously. This is more efficient than reading files one by one when you need to analyze or compare multiple files. Each file's content is returned with its path as a reference. Failed reads for individual files won't stop the entire operation. Only works within allowed directories.\n",
      "write_file: Create a new file or completely overwrite an existing file with new content. Use with caution as it will overwrite existing files without warning. Handles text content with proper encoding. Only works within allowed directories.\n",
      "edit_file: Make line-based edits to a text file. Each edit replaces exact line sequences with new content. Returns a git-style diff showing the changes made. Only works within allowed directories.\n",
      "create_directory: Create a new directory or ensure a directory exists. Can create multiple nested directories in one operation. If the directory already exists, this operation will succeed silently. Perfect for setting up directory structures for projects or ensuring required paths exist. Only works within allowed directories.\n",
      "list_directory: Get a detailed listing of all files and directories in a specified path. Results clearly distinguish between files and directories with [FILE] and [DIR] prefixes. This tool is essential for understanding directory structure and finding specific files within a directory. Only works within allowed directories.\n",
      "directory_tree: Get a recursive tree view of files and directories as a JSON structure. Each entry includes 'name', 'type' (file/directory), and 'children' for directories. Files have no children array, while directories always have a children array (which may be empty). The output is formatted with 2-space indentation for readability. Only works within allowed directories.\n",
      "move_file: Move or rename files and directories. Can move files between directories and rename them in a single operation. If the destination exists, the operation will fail. Works across different directories and can be used for simple renaming within the same directory. Both source and destination must be within allowed directories.\n",
      "search_files: Recursively search for files and directories matching a pattern. Searches through all subdirectories from the starting path. The search is case-insensitive and matches partial names. Returns full paths to all matching items. Great for finding files when you don't know their exact location. Only searches within allowed directories.\n",
      "get_file_info: Retrieve detailed metadata about a file or directory. Returns comprehensive information including size, creation time, last modified time, permissions, and type. This tool is perfect for understanding file characteristics without reading the actual content. Only works within allowed directories.\n",
      "list_allowed_directories: Returns the list of directories that this server is allowed to access. Use this to understand which directories are available before trying to access files.\n"
     ]
    }
   ],
   "source": [
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "files_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]}\n",
    "\n",
    "file_tools = await get_tools(files_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "browser_close: Close the page\n",
      "browser_resize: Resize the browser window\n",
      "browser_console_messages: Returns all console messages\n",
      "browser_handle_dialog: Handle a dialog\n",
      "browser_file_upload: Upload one or multiple files\n",
      "browser_install: Install the browser specified in the config. Call this if you get an error about the browser not being installed.\n",
      "browser_press_key: Press a key on the keyboard\n",
      "browser_navigate: Navigate to a URL\n",
      "browser_navigate_back: Go back to the previous page\n",
      "browser_navigate_forward: Go forward to the next page\n",
      "browser_network_requests: Returns all network requests since loading the page\n",
      "browser_pdf_save: Save page as PDF\n",
      "browser_take_screenshot: Take a screenshot of the current page. You can't perform actions based on the screenshot, use browser_snapshot for actions.\n",
      "browser_snapshot: Capture accessibility snapshot of the current page, this is better than screenshot\n",
      "browser_click: Perform click on a web page\n",
      "browser_drag: Perform drag and drop between two elements\n",
      "browser_hover: Hover over element on page\n",
      "browser_type: Type text into editable element\n",
      "browser_select_option: Select an option in a dropdown\n",
      "browser_tab_list: List browser tabs\n",
      "browser_tab_new: Open a new tab\n",
      "browser_tab_select: Select a tab by index\n",
      "browser_tab_close: Close a tab\n",
      "browser_generate_playwright_test: Generate a Playwright test for given scenario\n",
      "browser_wait_for: Wait for text to appear or disappear or a specified time to pass\n"
     ]
    }
   ],
   "source": [
    "playwright_params = {\"command\":\"npx\", \"args\":[\"-y\", \"@playwright/mcp@latest\"]}\n",
    "\n",
    "playwright_tools = await get_tools(playwright_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now.. bring on the Agent with Tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 74701a8c35f6: 100% ▕██████████████████▏ 1.3 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 4f659a1e86d7: 100% ▕██████████████████▏  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import OpenAIChatCompletionsModel, AsyncOpenAI\n",
    "\n",
    "# Create a client that talks to your local Ollama server\n",
    "llm_client = AsyncOpenAI(\n",
    "    base_url=os.getenv(\"OLLAMA_URL\"),  # Ollama's OpenAI-compatible endpoint\n",
    "    api_key=os.getenv(\"OLLAMA_API_KEY\"),  # Any string works, it's not authenticated\n",
    ")\n",
    "\n",
    "# Specify the Ollama model you want to use\n",
    "llm_model = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"OLLAMA_LLAMA3_2\"),  # or llama3, mistral, etc.\n",
    "    openai_client=llm_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Banoffee Pie Recipe\n",
      "\n",
      "## Ingredients:\n",
      "\n",
      "* 250g readymade sponge cake\n",
      "* 150g butter, softened\n",
      "* 150g golden syrup\n",
      "* 150g cream\n",
      "* 100g chocolate chips\n",
      "* 100g chopped dates\n",
      "* 2 tablespoons golden caster sugar\n",
      "* 1 teaspoon vanilla extract\n",
      "* Whipping cream for serving\n",
      "\n",
      "## Instructions:\n",
      "\n",
      "1. Preheat the oven to 180°C (160°C fan-forced).\n",
      "2. Cut the cake into small pieces and place in a bowl.\n",
      "3. Melt the butter and golden syrup in a saucepan over low heat, stirring occasionally.\n",
      "4. Remove from heat and stir in the cream until it's fully incorporated.\n",
      "5. Push the mixture to one side of the bowl.\n",
      "6. Add the chopped dates and golden caster sugar to the other side of the bowl.\n",
      "7. Stir gently to combine.\n",
      "8. Fold in the chocolate chips into the date mixture.\n",
      "9. Pour the mixture over the cooled cake pieces in the bowl.\n",
      "10. Refrigerate for at least 30 minutes or until set.\n",
      "11. Whip heavy cream until it forms stiff peaks.\n",
      "12. Spread or pipe whipped cream over the top of the banoffee pie.\n",
      "\n",
      "## Notes:\n",
      "\n",
      "* You can use store-bought whipped cream if you prefer.\n",
      "* Adjust the amount of golden syrup to your taste.\n",
      "* If using pre-made chocolate ice cream, place a layer on top and chill until set before serving.\n"
     ]
    }
   ],
   "source": [
    "#System prompt\n",
    "instructions = \"\"\"\n",
    "You browse the internet to accomplish your instructions.\n",
    "You are highly capable at browsing the internet independently to accomplish your task,\n",
    "including accepting all cookies and clicking 'not now' as\n",
    "appropriate to get to the content you need. If one website isn't fruitful, try another.\n",
    "Be persistent until you have solved your assignment,\n",
    "trying different options and sites as needed.\n",
    "\"\"\"\n",
    "\n",
    "async with MCPServerStdio(params=files_params, cache_tools_list=True) as mcp_server_files:\n",
    "    async with MCPServerStdio(params=playwright_params, cache_tools_list=True) as mcp_server_browser:\n",
    "        agent = Agent(\n",
    "            name=\"investigator\",\n",
    "            instructions=instructions,\n",
    "            model=llm_model,\n",
    "            mcp_servers=[mcp_server_files, mcp_server_browser]\n",
    "            )\n",
    "        with trace(\"investigate\"):\n",
    "            result = await Runner.run(\n",
    "                agent,\n",
    "                \"Find a great recipe for Banoffee Pie, then summarize it in markdown to banoffee1.md\"\n",
    "                )\n",
    "            print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
